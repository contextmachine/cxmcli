import json
import random
import uuid
import os
import ifcopenshell
import numpy as np
import ujson
from ifcopenshell import geom
from OCC.Core.Tesselator import ShapeTesselator
from mmcore.base import AGroup, AMesh
from mmcore.geom.materials import ColorRGB
from mmcore.base import create_buffer_from_dict
from pathlib import Path
import os

NAME = "export"
EXPORT_PATH = f"{os.getcwd()}/mm-ifcexport"
from mmcore.geom.plane import create_plane, world_to_local, local_to_world, vectorize, rotate_plane
from mmcore.base.models.gql import create_shape_buffer, update_shape_buffer, create_material, create_uvlike_buffer, \
    MeshPhongMaterial, create_buffer_color
from mmcore.geom.mesh import MeshTuple, union_mesh, create_mesh_tuple

from mmcore.compat.gltf.convert import create_union_mesh_node, create_scene_from_meshes, asscene


def create_union_mesh(uuid, meshes, ks=('position',)):
    r = union_mesh(meshes, ks)
    vm = create_material(amatdict, uuid + '-mat', (250, 250, 250), vertexColors=True)
    m = AMesh(uuid=uuid,
              geometry=create_shape_buffer(uuid + '-geom',
                                           position=r.attributes['position'].tolist(),
                                           color=r.attributes['color'].tolist(),
                                           index=r.indices.tolist()),

              material=vm)
    m.add_userdata_item('parts', r.extras['parts'].tolist())
    return m


vertexMaterial = MeshPhongMaterial(uuid='vxmat', color=ColorRGB(200, 200, 200).decimal, vertexColors=True, side=2)


def props(f):
    props = dict(context=f.data.context, type=f.data.type, parent_id=f.data.parent_id)
    for k in f.data.product.get_attribute_names():
        val = f.data.product.get_argument(k)

        props[k] = f'{val}'

    return props


from mmcore.base.registry import objdict, amatdict, ageomdict

cb = lambda nam: nam.split(":")[0]

DISABLE_TRIANGULATION = True
NO_WIRE_INTERSECTION_CHECK = True
COMPRESSED = False


def thr(source, path=EXPORT_PATH, prefix=NAME, file_names=()):
    colors = {}
    nms = {}

    support_attributes = dict()

    fl = ifcopenshell.open(source)
    settings = geom.settings(USE_PYTHON_OPENCASCADE=True, DISABLE_TRIANGULATION=True,
                             NO_WIRE_INTERSECTION_CHECK=NO_WIRE_INTERSECTION_CHECK)

    itr = geom.iterate(file_or_filename=fl, settings=settings)

    for i, o in enumerate(itr):

        try:

            _name = cb(o.data.name)
            if any([_name == "", _name is None]):
                _name = f"Undefined-{i}"

            _name = _name.replace("/", "-").replace("\\", "-")
            if _name not in nms.keys():
                nms[_name] = []
                if o.styles:
                    r, g, b, a = o.styles[0]
                    colors[_name] = r, g, b
                else:
                    colors[_name] = random.random(), random.random(), random.random()

                # amatdict[hex(hash(_name)) + "_mat"] = AMesh.material_type(uuid=hex(hash(_name)) + "_mat",
                # color=colors[_name])
            gmuid = uuid.uuid4().hex

            tess = ShapeTesselator(o.geometry)
            tess.Compute(compute_edges=False,
                         mesh_quality=1.0,
                         parallel=True)

            data = json.loads(tess.ExportShapeToThreejsJSONString(gmuid))
            attributes = dict()
            ixs = None

            for k, d in data['data']['attributes'].items():
                # buff[k].extend(d['array'])

                # _parts.extend((np.ones(len(d['array']))*mn).tolist())

                attributes[k] = d['array']
            if 'index' in data['data']:
                ixs = data['data']['array']

            msh = create_mesh_tuple(attributes, ixs, color=colors[_name])
            if not (len(_name) > 0):
                _name = uuid.uuid4().hex
            support_attributes[_name] = list(attributes.keys()) + ['color']
            nms[_name].append(msh)

            print(f'export {i} item {_name}', flush=True, end="\r")
        except Exception as err:
            print(err)
            pass

    print("\nbuilding meshes ...")
    meshes = build_meshes(nms=nms,
                          support_attributes=support_attributes,
                          filenames=file_names)
    print("\ndump to filesystem ...")
    dump_all_to_fs(path=path,
                   name=prefix,
                   meshes=meshes,
                   support_attributes=support_attributes)

    print("done!\n")


def dump_group(name, nms):
    return nms[name].root()


def build_mesh_with_buffer(mesh: MeshTuple, name: str):
    uid = uuid.uuid4().hex

    create_uvlike_buffer(amatdict, **{k: attr.tolist() for k, attr in mesh.attributes.items()},
                         uuid=uid)
    return AMesh(uuid=uid + 'mesh',
                 name=name,
                 geometry=ageomdict[uid],
                 material=vertexMaterial)


def build_meshes(nms, support_attributes, filenames=()) -> dict:
    meshes = dict()
    names = []

    for k, n in nms.items():

        if len(filenames) > 0:

            if k in filenames:
                names.append(k)
                u = union_mesh(n, support_attributes[k])
                meshes[k] = u


        else:

            u = union_mesh(n, support_attributes[k])

            meshes[k] = u

    return meshes


def dump_all_to_fs(path, name, meshes, support_attributes):
    grp = AGroup(uuid=f'{name}-group', name=name)
    for k, msh in meshes.items():
        amesh = build_mesh_with_buffer(msh, k)
        amesh.dump(f"{path}/{k}.json")
        grp.add(amesh)
    grp.dump(path + '/' + name + "_all.json")
    all_attrs = tuple(set.intersection(*(set(val) for val in support_attributes.values())))
    print(all_attrs)
    joined = union_mesh(list(meshes.values()), all_attrs)
    amesh = build_mesh_with_buffer(joined, name)
    amesh.dump(path + '/' + name + "_joined_all.json")


import click
from datetime import datetime


def export_file(source, name, use_last):
    file_names = []
    if name == "FROM_SOURCE":
        target_path = source.split('/')[-1].split('.')[0]
    else:
        target_path = name
    prefix = target_path.split('/')[-1]
    if not os.path.exists(target_path):
        Path(target_path).mkdir(parents=True, exist_ok=True)
    else:
        if use_last:
            for fl in os.scandir(target_path):
                file_names.append(fl.name.replace('.json', ''))

    thr(source=source, prefix=prefix, path=target_path, file_names=file_names)


import rich

import multiprocess as mp
def _export_file_mp(args):
    source, name, use_last=args
    export_file(source, name, use_last)
def exporter(source, name, multiply, use_last):


    if multiply:
        print('üõ†Ô∏è prepare multiply export ...')
        sources = []
        for item in os.scandir(source):
            if item.name.lower().endswith('.ifc'):
                sources.append((item.path, f'{name}/{item.name}',use_last))
        print("\n" + ('-' * 140) + '\ntasks:\n\n')
        rich.print(sources)
        print('starting... \n')
        with mp.Pool(len(sources)) as pool:
            pool.map(_export_file_mp, sources)


    else:
        print(f"üõ†Ô∏è {source} -> {name}")
        export_file(source=source,
                    name=name,
                    use_last=use_last)
    print('-' * 80 + '\nüõ† all tasks done!')


@click.command()
@click.argument('source')
@click.option('--name', default="FROM_SOURCE",
              help='–ê–±—Å–æ–ª—é—é—Ç–Ω—ã–π –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –∫–æ—Ç–æ—Ä—É—é —Å–ª–µ–¥—É–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å. '
                   '\n–ó–Ω–∞—á–µ–Ω–∏–µ FROM_SOURCE –∑–∞—Å—Ç–∞–≤–∏—Ç —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–º—è —Ç–µ–∫—É—â–µ–≥–æ '
                   '\n—Ñ–∞–π–ª–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–º–µ–Ω–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏. –ë—É–¥—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã, '
                   '\n–µ—Å–ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã, '
                   '\n—Ç–∞–∫–∏–µ –∫–∞–∫: [\\/,.] –∏–ª–∏ –Ω–µ —Å–∏–º–≤–æ–ª—ã utf-8, —ç–∫—Å–ø–æ—Ä—Ç –º–æ–∂–µ—Ç '
                   '\n–∑–∞–∫–æ–Ω—á–∏—Ç—å—Å—è –æ—à–∏–±–∫–æ–π.\n\n')
@click.option('--multiply', is_flag=True, default=0, help='–í–∫–ª—é—á–∞–µ—Ç –æ–ø—Ü–∏—é –º—É–ª—å—Ç–∏-—ç–∫—Å–ø–æ—Ä—Ç–∞. –ü–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –ø–µ—Ä–≤—ã–º '
                                                          '\n–∞—Ä–≥—É–º–µ–Ω—Ç–æ–º –ø—É—Ç—å –±—É–¥–µ—Ç –≤–æ—Å–ø—Ä–∏–Ω—è—Ç –∫–∞–∫ –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏. –í—Å–µ '
                                                          '\n–Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è —Ç–∞–º —Ñ–∞–π–ª—ã, –∫–∞–∫ —Ñ–∞–π–ª—ã ifc. –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –¥–æ–ª–∂–Ω–∞ '
                                                          '\n—Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ —Ñ–∞–π–ª–æ–≤ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞. '
                                                          '\n–û–ø—Ü–∏—è --name –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ '
                                                          '\n–∫–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞.\n\n')
@click.option('--use-last', is_flag=True, default=0, help='–ë—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ç–µ —Ñ–∞–π–ª—ã –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ '
                                                          '\n—ç–∫—Å–ø–æ—Ä—Ç–Ω–æ–π –ø–∞–ø–∫–µ. –û—Å—Ç–∞–ª—å–Ω—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã.\n\n')
def cli(source, name, multiply, use_last):
    print('üõ†Ô∏è arguments: \n')
    rich.print(dict(source=source, name=name, multiply=multiply, use_last=use_last))
    exporter(source, name, multiply, use_last)


if __name__ == "__main__":
    cli()
